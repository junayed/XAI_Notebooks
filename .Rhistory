knitr::opts_chunk$set(echo = TRUE)
library(OneR)
library(dplyr)
library(tidyverse)
setwd("D:/Machine_Learning/Projects/XAI Samples")
data_17 <- read.table("data/world-happiness-2017.csv", sep = ",", header = TRUE)
data_16 <- read.table("data/world-happiness-2016.csv", sep = ",", header = TRUE)
data_15 <- read.table("data/world-happiness-2015.csv", sep = ",", header = TRUE)
common_feats <- colnames(data_16)[which(colnames(data_16) %in% colnames(data_15))]
# features and response variable for modeling
feats <- setdiff(common_feats, c("Country", "Happiness.Rank", "Happiness.Score"))
response <- "Happiness.Score"
# combine data from 2015 and 2016
data_15_16 <- rbind(select(data_15, one_of(c(feats, response))),
select(data_16, one_of(c(feats, response))))
data_15_16$Happiness.Score.l <- bin(data_15_16$Happiness.Score, nbins = 3, method = "content")
intervals <- paste(levels(data_15_16$Happiness.Score.l), collapse = " ")
intervals <- gsub("\\(|]", "", intervals)
intervals <- gsub(",", " ", intervals)
intervals <- as.numeric(unique(strsplit(intervals, " ")[[1]]))
data_15_16 %>%
ggplot() +
geom_density(aes(x = Happiness.Score), color = "blue", fill = "blue", alpha = 0.4) +
geom_vline(xintercept = intervals[2]) +
geom_vline(xintercept = intervals[3])
data_15_16 <- select(data_15_16, -Happiness.Score) %>%
mutate(Happiness.Score.l = plyr::revalue(Happiness.Score.l, c("(2.83,4.79]" = "low", "(4.79,5.89]" = "medium", "(5.89,7.59]" = "high")))
data_15_16 %>%
ggplot(aes(x = Region, fill = Happiness.Score.l)) +
geom_bar(position = "dodge", alpha = 0.7) +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
plot.margin = unit(c(0, 0, 0, 1.5), "cm")) +
scale_fill_brewer(palette = "Set1")
data_15_16 %>%
gather(x, y, Economy..GDP.per.Capita.:Dystopia.Residual) %>%
ggplot(aes(x = y, fill = Happiness.Score.l)) +
geom_histogram(alpha = 0.7) +
facet_wrap(~ x, scales = "free", ncol = 4) +
scale_fill_brewer(palette = "Set1")
data_15_16 <- select(data_15_16, -Region)
set.seed(42)
index <- createDataPartition(data_15_16$Happiness.Score.l, p = 0.7, list = FALSE)
set.seed(42)
library(caret)
index <- createDataPartition(data_15_16$Happiness.Score.l, p = 0.7, list = FALSE)
train_data <- data_15_16[index, ]
test_data  <- data_15_16[-index, ]
# default method length
data_1 <- bin(train_data, nbins = 5, method = "length")
# method content
data_2 <- bin(train_data, nbins = 5, method = "content")
# method cluster
data_3 <- bin(train_data, nbins = 3, method = "cluster")
# optimal bin number logistic regression
data_4 <- optbin(formula = Happiness.Score.l ~., data = train_data, method = "logreg")
# optimal bin number information gain
data_5 <- optbin(formula = Happiness.Score.l ~., data = train_data, method = "infogain")
for (i in 1:5) {
data <- get(paste0("data_", i))
print(model <- OneR(formula = Happiness.Score.l ~., data = data, verbose = TRUE))
assign(paste0("model_", i), model)
}
##
##     Attribute                     Accuracy
## 1 * Economy..GDP.per.Capita.      63.96%
## 2   Health..Life.Expectancy.      59.91%
## 3   Family                        57.21%
## 4   Dystopia.Residual             51.8%
## 5   Freedom                       49.55%
## 6   Trust..Government.Corruption. 45.5%
## 7   Generosity                    41.89%
## ---
## Chosen attribute due to accuracy
## and ties method (if applicable): '*'
##
##
## Call:
##OneR(data_1, data = data, formula = Happiness.Score.l ~ ., verbose = TRUE)
##
## Rules:
## If Economy..GDP.per.Capita. = (-0.00182,0.365] then Happiness.Score.l = low
## If Economy..GDP.per.Capita. = (0.365,0.73]     then Happiness.Score.l = low
## If Economy..GDP.per.Capita. = (0.73,1.09]      then Happiness.Score.l = medium
## If Economy..GDP.per.Capita. = (1.09,1.46]      then Happiness.Score.l = high
## If Economy..GDP.per.Capita. = (1.46,1.83]      then Happiness.Score.l = high
##
## Accuracy:
## 142 of 222 instances classified correctly (63.96%)
##
##
##     Attribute                     Accuracy
## 1 * Economy..GDP.per.Capita.      64.41%
## 2   Health..Life.Expectancy.      60.81%
## 3   Family                        59.91%
## 4   Trust..Government.Corruption. 55.41%
## 5   Freedom                       53.15%
## 5   Dystopia.Residual             53.15%
## 7   Generosity                    41.44%
## ---
## Chosen attribute due to accuracy
## and ties method (if applicable): '*'
##
##
## Call:
## OneR(data_2, data = data, formula = Happiness.Score.l ~ ., verbose = TRUE)
##
## Rules:
## If Economy..GDP.per.Capita. = (-0.00182,0.548] then Happiness.Score.l = low
## If Economy..GDP.per.Capita. = (0.548,0.877]    then Happiness.Score.l = low
## If Economy..GDP.per.Capita. = (0.877,1.06]     then Happiness.Score.l = medium
## If Economy..GDP.per.Capita. = (1.06,1.28]      then Happiness.Score.l = medium
## If Economy..GDP.per.Capita. = (1.28,1.83]      then Happiness.Score.l = high
##
## Accuracy:
## 143 of 222 instances classified correctly (64.41%)
##
##
##     Attribute                     Accuracy
## 1 * Economy..GDP.per.Capita.      63.51%
## 2   Health..Life.Expectancy.      62.16%
## 3   Family                        54.5%
## 4   Freedom                       50.45%
## 4   Dystopia.Residual             50.45%
## 6   Trust..Government.Corruption. 43.24%
## 7   Generosity                    36.49%
## ---
## Chosen attribute due to accuracy
## and ties method (if applicable): '*'
##
##
## Call:
## OneR(data_3, data = data, formula = Happiness.Score.l ~ ., verbose = TRUE)
##
## Rules:
## If Economy..GDP.per.Capita. = (-0.00182,0.602] then Happiness.Score.l = low
## If Economy..GDP.per.Capita. = (0.602,1.1]      then Happiness.Score.l = medium
## If Economy..GDP.per.Capita. = (1.1,1.83]       then Happiness.Score.l = high
##
## Accuracy:
## 141 of 222 instances classified correctly (63.51%)
##
##
##     Attribute                     Accuracy
## 1 * Economy..GDP.per.Capita.      63.96%
## 2   Health..Life.Expectancy.      62.16%
## 3   Family                        58.56%
## 4   Freedom                       51.35%
## 5   Dystopia.Residual             50.9%
## 6   Trust..Government.Corruption. 46.4%
## 7   Generosity                    40.09%
## ---
## Chosen attribute due to accuracy
## and ties method (if applicable): '*'
##
##
## Call:
## OneR(data_4, data = data, formula = Happiness.Score.l ~ ., verbose = TRUE)
##
## Rules:
## If Economy..GDP.per.Capita. = (-0.00182,0.754] then Happiness.Score.l = low
## If Economy..GDP.per.Capita. = (0.754,1.12]     then Happiness.Score.l = medium
## If Economy..GDP.per.Capita. = (1.12,1.83]      then Happiness.Score.l = high
##
## Accuracy:
## 142 of 222 instances classified correctly (63.96%)
##
##
##     Attribute                     Accuracy
## 1 * Economy..GDP.per.Capita.      67.12%
## 2   Health..Life.Expectancy.      65.77%
## 3   Family                        61.71%
## 4   Trust..Government.Corruption. 56.31%
## 5   Dystopia.Residual             55.41%
## 6   Freedom                       50.9%
## 7   Generosity                    43.69%
## ---
## Chosen attribute due to accuracy
## and ties method (if applicable): '*'
##
##
## Call:
## OneR(data_5, data = data, formula = Happiness.Score.l ~ ., verbose = TRUE)
##
## Rules:
## If Economy..GDP.per.Capita. = (-0.00182,0.68] then Happiness.Score.l = low
## If Economy..GDP.per.Capita. = (0.68,1.24]     then Happiness.Score.l = medium
## If Economy..GDP.per.Capita. = (1.24,1.83]     then Happiness.Score.l = high
##
## Accuracy:
## 149 of 222 instances classified correctly (67.12%)
for (i in 1:5) {
model <- get(paste0("model_", i))
eval_model(predict(model, test_data), test_data$Happiness.Score.l)
}
for (i in 1:5) {
model <- get(paste0("model_", i))
pred <- data.frame(model = paste0("model_", i),
sample_id = 1:nrow(test_data),
predict(model, test_data, type = "prob"),
actual = test_data$Happiness.Score.l)
pred$prediction <- colnames(pred)[3:5][apply(pred[, 3:5], 1, which.max)]
pred$correct <- ifelse(pred$actual == pred$prediction, "correct", "wrong")
pred$pred_prob <- NA
for (j in 1:nrow(pred)) {
pred[j, "pred_prob"] <- max(pred[j, 3:5])
}
if (i == 1) {
pred_df <- pred
} else {
pred_df <- rbind(pred_df, pred)
}
}
View(pred)
library(rpart)
library(rpart.plot)
set.seed(42)
fit <- rpart(Happiness.Score.l ~ .,
data = train_data,
method = "class",
control = rpart.control(xval = 10),
parms = list(split = "information"))
rpart.plot(fit, extra = 100)
set.seed(42)
model_nn <- caret::train(Happiness.Score.l ~ .,
data = train_data,
method = "mlp",
trControl = trainControl(method = "repeatedcv",
number = 10,
repeats = 5,
verboseIter = FALSE))
varImp(model_nn)
pred <- data.frame(model = "nn",
sample_id = 1:nrow(test_data),
predict(model_nn, test_data, type = "prob"),
actual = test_data$Happiness.Score.l)
pred$prediction <- colnames(pred)[3:5][apply(pred[, 3:5], 1, which.max)]
pred$correct <- ifelse(pred$actual == pred$prediction, "correct", "wrong")
pred$pred_prob <- NA
for (j in 1:nrow(pred)) {
pred[j, "pred_prob"] <- max(pred[j, 3:5])
}
pred_df_final <- rbind(pred_df_final,
pred)
View(pred)
library(lime)
library(tidyverse)
explainer <- lime(train_data, model_nn, bin_continuous = TRUE, n_bins = 5, n_permutations = 1000)
pred_cor <- filter(pred, correct == "correct")
pred_wrong <- filter(pred, correct == "wrong")
test_data_cor <- test_data %>%
mutate(sample_id = 1:nrow(test_data)) %>%
filter(sample_id %in% pred_cor$sample_id) %>%
sample_n(size = 3) %>%
remove_rownames() %>%
tibble::column_to_rownames(var = "sample_id") %>%
select(-Happiness.Score.l)
test_data_wrong <- test_data %>%
mutate(sample_id = 1:nrow(test_data)) %>%
filter(sample_id %in% pred_wrong$sample_id) %>%
sample_n(size = 3) %>%
remove_rownames() %>%
tibble::column_to_rownames(var = "sample_id") %>%
select(-Happiness.Score.l)
explanation_cor <- explain(test_data_cor, explainer, n_labels = 3, n_features = 5)
explanation_wrong <- explain(test_data_wrong, explainer, n_labels = 3, n_features = 5)
plot_features(explanation_cor, ncol = 3)
plot_features(explanation_wrong, ncol = 3)
set.seed(42)
model_xgb <- caret::train(Happiness.Score.l ~ .,
data = train_data,
method = "xgbTree",
trControl = trainControl(method = "repeatedcv",
number = 10,
repeats = 5,
verboseIter = FALSE))
pred <- data.frame(model = "nn",
sample_id = 1:nrow(test_data),
predict(model_nn, test_data, type = "prob"),
actual = test_data$Happiness.Score.l)
pred$prediction <- colnames(pred)[3:5][apply(pred[, 3:5], 1, which.max)]
pred$correct <- ifelse(pred$actual == pred$prediction, "correct", "wrong")
pred$pred_prob <- NA
for (j in 1:nrow(pred)) {
pred[j, "pred_prob"] <- max(pred[j, 3:5])
}
